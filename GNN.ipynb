{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05bacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries, modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec36113",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Class for loading data\n",
    "################################################################################\n",
    "from spektral.data import Dataset, Graph\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, n_samples, feats, path, **kwargs):\n",
    "        self.n_samples = n_samples\n",
    "        self.feats = feats\n",
    "        self.path = path\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        def make_graph(i):\n",
    "            feature=np.loadtxt(self.path+'GNN_inputs_RVE_'+str(i+1)+'.csv',delimiter=',')\n",
    "            num_grains=int(len(feature)/6)\n",
    "            feature=feature.reshape((num_grains,6)) #reshape the feature matrix\n",
    "            \n",
    "            neigbor=np.loadtxt(self.path+'Neighbor_matrix_RVE_'+str(i+1)+'.csv',delimiter=',')\n",
    "            neigbor=neigbor.reshape((num_grains,num_grains))\n",
    "     \n",
    "            stress=np.loadtxt(self.path+'stress_output.csv',delimiter=',')\n",
    "            y=np.array(stress[i])\n",
    "            \n",
    "            return Graph(x=feature, a=neigbor, y=y)\n",
    "\n",
    "        # We must return a list of Graph objects\n",
    "        return [make_graph(i) for i in range(self.n_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bce86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Load dataset\n",
    "################################################################################\n",
    "from spektral.transforms.normalize_adj import NormalizeAdj\n",
    "\n",
    "num_RVEs=2000\n",
    "num_features=5\n",
    "#directory of input files\n",
    "path=''\n",
    "dataset = MyDataset(num_RVEs,num_features, path, transforms=NormalizeAdj())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91752e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data import DisjointLoader, BatchLoader\n",
    "# Parameters\n",
    "F = dataset.n_node_features  # Dimension of node features\n",
    "S = dataset.n_edge_features  # Dimension of edge features\n",
    "n_out = dataset.n_labels  # Dimension of the target\n",
    "\n",
    "# Train/test split\n",
    "idxs = np.random.permutation(len(dataset))\n",
    "split = int(0.75 * len(dataset))\n",
    "idx_tr, idx_te = np.split(idxs, [split])\n",
    "dataset_tr, dataset_te = dataset[idx_tr], dataset[idx_te]\n",
    "\n",
    "batch_size = 32\n",
    "loader_tr = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=5000)\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f11a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Build model\n",
    "################################################################################\n",
    "from spektral.layers import GCSConv, GlobalAvgPool, GlobalSumPool, GraphMasking\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "class Net(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCSConv(64, activation=\"relu\")\n",
    "        self.conv2 = GCSConv(128, activation=\"relu\")\n",
    "        #self.conv3 = GCSConv(256, activation=\"relu\")\n",
    "        self.global_pool = GlobalSumPool()\n",
    "        self.dense = Dense(n_out)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a, i = inputs\n",
    "        x = self.conv1([x, a])\n",
    "        x = self.conv2([x, a])\n",
    "        #x = self.conv3([x, a])\n",
    "        output = self.global_pool([x,i])\n",
    "        output = self.dense(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b717ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Compile model\n",
    "################################################################################\n",
    "model = Net()\n",
    "learning_rate = 1e-3\n",
    "optimizer = Adam(learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Fit model\n",
    "################################################################################\n",
    "model.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Evaluate model\n",
    "################################################################################\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=batch_size, epochs=1)\n",
    "print(\"Testing model\")\n",
    "loss = 0\n",
    "Pred=np.array([])\n",
    "Targ=np.array([])\n",
    "for batch in loader_te:\n",
    "    inputs, target = batch\n",
    "    predictions = model(inputs, training=False)\n",
    "    Pred=np.append(Pred,predictions)\n",
    "    Targ=np.append(Targ,target)\n",
    "loss /= loader_te.steps_per_epoch\n",
    "print(\"Done. Test loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.xlabel('Actual stress (MPa)', fontsize=20)\n",
    "plt.ylabel('Predicted stress (MPa)', fontsize=20)\n",
    "plt.scatter(Targ,Pred)\n",
    "plt.plot(Targ,Targ,'r')\n",
    "plt.savefig('GNN_uni.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score\n",
    "print(mean_absolute_error(Targ,Pred))\n",
    "print(np.sqrt(mean_squared_error(Targ,Pred)))\n",
    "print(explained_variance_score(Targ,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde9a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8ee89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86287d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
